{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:3em;\">Ch4: Real-world data\n",
    " representation\n",
    " using tensors</span>\n",
    " \n",
    " Each section in this chapter will describe a data type, and each will come with its\n",
    "own dataset. We’ll be using a lot of image and volumetric data through the rest of the book,\n",
    "since those are common data types and they reproduce well in book format. We’ll also\n",
    "cover tabular data, time series, and text, as those will also be of interest to a number of\n",
    "our readers. \n",
    "\n",
    "In every section, we will stop where a deep learning researcher would start: right\n",
    "before feeding the data to a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Working with Images\n",
    "\n",
    "## 4.1.1Images as an array\n",
    " An image is represented as a collection of scalars arranged in a regular grid with a\n",
    "height and a width (in pixels). We might have a single scalar per grid point (the\n",
    "pixel), which would be represented as a grayscale image; or multiple scalars per grid\n",
    "point, which would typically represent different colors, as we saw in the previous chapter, or different features like depth from a depth camera.\n",
    "\n",
    "Scalars representing values at individual pixels are often encoded using 8-bit integers, as in consumer cameras. In medical, scientific, and industrial applications, it is\n",
    "not unusual to find higher numerical precision, such as 12-bit or 16-bit. This allows a\n",
    "wider range or increased sensitivity in cases where the pixel encodes information\n",
    "about a physical property, like bone density, temperature, or depth.\n",
    "\n",
    "## 4.1.2 Loading an Image file\n",
    "Images come in several different file formats, but luckily there are plenty of ways to\n",
    "load images in Python. Let’s start by loading a PNG image using the <b>imageio</b> module\n",
    "\n",
    "<b>NOTE:</b> We’ll use imageio throughout the chapter because it handles different\n",
    "data types with a uniform API. For many purposes, using TorchVision is a\n",
    "great default choice to deal with image and video data. We go with imageio\n",
    "here for somewhat lighter exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr = imageio.imread('../dlwpt-code/data/p1ch4/image-dog/bobby.jpg')\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, img is a NumPy array-like object with three dimensions: two spatial\n",
    "dimensions, width and height; and a third dimension corresponding to the red,\n",
    "green, and blue channels. Any library that outputs a NumPy array will suffice to obtain\n",
    "a PyTorch tensor. \n",
    "\n",
    "## 4.1.3 Changing the Layout\n",
    "\n",
    "The only thing to watch out for is the layout of the dimensions.\n",
    "PyTorch modules dealing with image data require tensors to be laid out as <b>C × H × W </b>:\n",
    "channels, height, and width, respectively. (TensorFlow is H x W C but it doesnt make a huge difference, need to just make sure we change the layout accordingly)\n",
    "\n",
    "\n",
    "We can use the tensor’s permute method with the old dimensions for each new dimension to get to an appropriate layout. Given an input tensor H × W × C as obtained previously, we get a proper layout by having channel 2 first and then channels 0 and 1:\n",
    "\n",
    "Changing the layout using <b> permute</b> does not make a copy and instead uses the same storage and only changes size and stride. This means this operation is extremely cheap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2,0,1)\n",
    "\n",
    "#Note: Changing a pixel in img will change out since its not a copy but a new view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a dataset of multiple images to use as an input for our\n",
    "neural networks, we store the images in a batch along the first dimension to obtain an\n",
    "N × C × H × W tensor. An slightly more efficient alternative to using \"stack\" is to <b>preallocate a tensor of the appropriate size and shape and fill it with images loaded from the directory</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)\n",
    "\n",
    "#We can now load all PNG images from an input directory and store them in the tensor:\n",
    "import os\n",
    "\n",
    "data_dir = '../dlwpt-code/data/p1ch4/image-cats/'\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.png']\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2,0,1)\n",
    "    img_t = img_t[:3]\n",
    "    batch[i] = img_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.4 Normalizing the Data\n",
    "Neural networks exhibit the best training performance when the input\n",
    "data ranges roughly from 0 to 1, or from -1 to 1 (this is an effect of how their building\n",
    "blocks are defined).\n",
    " So a typical thing we’ll want to do is cast a tensor to floating-point and normalize\n",
    "the values of the pixels. Casting to floating-point is easy, but normalization is trickier,\n",
    "as it depends on what range of the input we decide should lie between 0 and 1 (or -1\n",
    "and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "batch /= 255.0\n",
    "\n",
    "n_channels = batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:,c])\n",
    "    std = torch.std(batch[:,c])\n",
    "    batch[:,c] = (batch[:,c] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NOTE</b> Here, we normalize just a single batch of images because we do not\n",
    "know yet how to operate on an entire dataset. In working with images, it is good\n",
    "practice to compute the mean and standard deviation on all the training data\n",
    "in advance and then subtract and divide by these fixed, precomputed quantities.\n",
    "\n",
    "We can perform several other operations on inputs, such as geometric transformations like rotations, scaling, and cropping. These may help with training or may be\n",
    "required to make an arbitrary input conform to the input requirements of a network,\n",
    "like the size of the image.\n",
    "\n",
    "# 3D Images: Volumetric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facial_rec",
   "language": "python",
   "name": "facial_rec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
